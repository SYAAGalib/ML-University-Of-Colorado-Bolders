{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Install required packages (run in Colab / notebook)\n",
        "# =========================================================\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install transformers timm\n",
        "!pip install torch-geometric -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "!pip install scikit-learn\n",
        "\n",
        "# =========================================================\n",
        "# TensorFlow imports (updated for newer versions)\n",
        "# =========================================================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "# Alternative imports for newer TensorFlow versions\n",
        "try:\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "except ImportError:\n",
        "    from tensorflow.keras.utils import ImageDataGenerator\n",
        "\n",
        "try:\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "except ImportError:\n",
        "    from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "# sklearn\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
        "                           matthews_corrcoef, roc_curve, auc, accuracy_score,\n",
        "                           precision_score, recall_score, f1_score)\n",
        "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Replace vit-keras with Hugging Face TF ViT\n",
        "from transformers import TFViTModel, ViTConfig\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# Alternative loss function import\n",
        "try:\n",
        "    from tensorflow.keras.losses import CategoricalFocalCrossentropy\n",
        "except ImportError:\n",
        "    CategoricalFocalCrossentropy = None\n",
        "\n",
        "# Check TensorFlow version and available devices\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "print('GPU Available:', tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Standard python imports used later\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import gc\n",
        "\n",
        "# Mount Google Drive (Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/New Plant Diseases Dataset(Augmented)/train'\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/New Plant Diseases Dataset(Augmented)/valid'\n",
        "\n",
        "if not os.path.exists(train_path):\n",
        "    print(f\"Warning: Training path {train_path} does not exist.\")\n",
        "    print(\"Please update the paths or upload your dataset to Google Colab.\")\n",
        "\n",
        "if not os.path.exists(test_path):\n",
        "    print(f\"Warning: Test path {test_path} does not exist.\")\n",
        "    print(\"Please update the paths or upload your dataset to Google Colab.\")\n",
        "\n",
        "def display_sample_images(path):\n",
        "    if os.path.exists(path):\n",
        "        disease_list = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
        "        if len(disease_list) > 0:\n",
        "            fig, axes = plt.subplots(2, 5, figsize=(15, 8))\n",
        "            fig.suptitle('Sample Images of Leaf Diseases', fontsize=16)\n",
        "            for i, disease in enumerate(disease_list[:10]):\n",
        "                disease_path = os.path.join(path, disease)\n",
        "                if os.path.exists(disease_path):\n",
        "                    images = [f for f in os.listdir(disease_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "                    if images:\n",
        "                        sample_image = random.choice(images)\n",
        "                        try:\n",
        "                            img = tf.keras.utils.load_img(os.path.join(disease_path, sample_image))\n",
        "                        except AttributeError:\n",
        "                            img = tf.keras.preprocessing.image.load_img(os.path.join(disease_path, sample_image))\n",
        "                        row, col = i // 5, i % 5\n",
        "                        if row < 2 and col < 5:\n",
        "                            axes[row, col].imshow(img)\n",
        "                            axes[row, col].set_title(disease, fontsize=12)\n",
        "                            axes[row, col].axis('off')\n",
        "            for i in range(len(disease_list), 10):\n",
        "                row, col = i // 5, i % 5\n",
        "                if row < 2 and col < 5:\n",
        "                    axes[row, col].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "    else:\n",
        "        print(f\"Path {path} not found. Skipping image display.\")\n",
        "\n",
        "# Display sample images\n",
        "display_sample_images(train_path)\n",
        "\n",
        "# Image Data Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Load datasets\n",
        "def create_data_generators():\n",
        "    try:\n",
        "        train_set = train_datagen.flow_from_directory(\n",
        "            train_path,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=32,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "        test_set = test_datagen.flow_from_directory(\n",
        "            test_path,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=32,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "        return train_set, test_set\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading datasets: {e}\")\n",
        "        print(\"Creating dummy datasets for demonstration...\")\n",
        "        # Create dummy data for testing\n",
        "        return None, None\n",
        "\n",
        "train_set, test_set = create_data_generators()\n",
        "\n",
        "def display_class_distribution(train_set):\n",
        "    if train_set is not None:\n",
        "        # Get class names and counts\n",
        "        disease_classes = list(train_set.class_indices.keys())\n",
        "        class_counts = []\n",
        "\n",
        "        for class_name in disease_classes:\n",
        "            class_dir = os.path.join(train_path, class_name)\n",
        "            if os.path.exists(class_dir):\n",
        "                num_images = len([f for f in os.listdir(class_dir)\n",
        "                                if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "                class_counts.append(num_images)\n",
        "            else:\n",
        "                class_counts.append(0)\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        bars = plt.bar(range(len(disease_classes)), class_counts)\n",
        "        plt.title('Class Distribution in Training Dataset')\n",
        "        plt.xlabel('Disease Classes')\n",
        "        plt.ylabel('Image Count')\n",
        "        plt.xticks(range(len(disease_classes)), disease_classes, rotation=45, ha='right')\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar, count in zip(bars, class_counts):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                    str(count), ha='center', va='bottom')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No training data available for class distribution plot.\")\n",
        "\n",
        "display_class_distribution(train_set)\n",
        "\n",
        "# Function definitions\n",
        "def predict_with_tta(model, image, n_aug=5):\n",
        "    \"\"\"Test Time Augmentation for better predictions\"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "    elif len(image.shape) == 4 and image.shape[0] == 1:\n",
        "        # Already has batch dimension\n",
        "        pass\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid image shape: {image.shape}\")\n",
        "\n",
        "    aug = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "\n",
        "    preds = []\n",
        "    try:\n",
        "        for _ in range(n_aug):\n",
        "            # Create augmented version\n",
        "            aug_img = aug.random_transform(image[0])\n",
        "            aug_img = np.expand_dims(aug_img, axis=0)\n",
        "            preds.append(model.predict(aug_img, verbose=0))\n",
        "\n",
        "        return np.mean(preds, axis=0)\n",
        "    except Exception as e:\n",
        "        print(f\"TTA failed, using original prediction: {e}\")\n",
        "        return model.predict(image, verbose=0)\n",
        "\n",
        "def get_features(generator, feature_extractor):\n",
        "    \"\"\"Extract features from data generator\"\"\"\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    print(\"Extracting features...\")\n",
        "    try:\n",
        "        for i in range(len(generator)):\n",
        "            x, y = generator[i]\n",
        "            batch_features = feature_extractor.predict(x, verbose=0)\n",
        "            features.append(batch_features)\n",
        "            labels.append(y)\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Processed batch {i+1}/{len(generator)}\")\n",
        "\n",
        "            # Clear memory periodically\n",
        "            if i % 50 == 0:\n",
        "                gc.collect()\n",
        "\n",
        "        return np.vstack(features), np.vstack(labels)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during feature extraction: {e}\")\n",
        "        if features and labels:\n",
        "            print(\"Returning partial features...\")\n",
        "            return np.vstack(features), np.vstack(labels)\n",
        "        else:\n",
        "            raise e\n",
        "\n",
        "class SimpleGNN(torch.nn.Module):\n",
        "    def __init__(self, num_features, hidden_dim, num_classes):\n",
        "        super(SimpleGNN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, num_classes)\n",
        "        self.dropout = 0.5\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training, p=self.dropout)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "def create_graph(features, k=5):\n",
        "    \"\"\"Create k-NN graph from features\"\"\"\n",
        "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(features)\n",
        "    distances, indices = nbrs.kneighbors(features)\n",
        "\n",
        "    # Remove self-connections\n",
        "    indices = indices[:, 1:]\n",
        "\n",
        "    sources = np.repeat(np.arange(len(features)), k)\n",
        "    targets = indices.flatten()\n",
        "    edge_index = torch.tensor(np.vstack([sources, targets]), dtype=torch.long)\n",
        "\n",
        "    return edge_index\n",
        "\n",
        "# =========================================================\n",
        "# Vision Transformer Model (Hugging Face TFViT replacement)\n",
        "# =========================================================\n",
        "def create_vit_model(num_classes):\n",
        "    \"\"\"Create and compile ViT model using Hugging Face TFViTModel\n",
        "       This replaces vit.vit_b16 from vit-keras to avoid tensorflow-addons dependency.\n",
        "    \"\"\"\n",
        "    # Load pretrained TF ViT backbone\n",
        "    config = ViTConfig.from_pretrained(\"google/vit-base-patch16-224\")\n",
        "    # set config.num_labels though we will add our own head\n",
        "    config.num_labels = num_classes\n",
        "    vit_backbone = TFViTModel.from_pretrained(\"google/vit-base-patch16-224\", from_pt=False, config=config)\n",
        "\n",
        "    # Freeze ViT backbone for transfer learning (same intent as original)\n",
        "    vit_backbone.trainable = False\n",
        "\n",
        "    # custom classification head (matches original head)\n",
        "    inputs = Input(shape=(224, 224, 3))\n",
        "    # Note: Your ImageDataGenerator already rescales images to [0,1], so pass inputs directly.\n",
        "    # If you prefer to match HF preprocess exactly, integrate ViTImageProcessor on raw images before model input.\n",
        "    vit_outputs = vit_backbone(inputs)  # TFViTModel returns a TFBaseModelOutput-like object\n",
        "    # Use CLS token embedding (position 0)\n",
        "    try:\n",
        "        x = vit_outputs.last_hidden_state[:, 0, :]  # [batch, hidden_dim]\n",
        "    except Exception:\n",
        "        # fallback if the output shape differs; try to flatten the backbone output\n",
        "        x = tf.keras.layers.Flatten()(vit_outputs[0])\n",
        "\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model, vit_backbone\n",
        "\n",
        "# Model Training and Evaluation Functions\n",
        "def evaluate_model_corrected(model, test_generator, model_name, is_hybrid=False):\n",
        "    \"\"\"Evaluate model performance\"\"\"\n",
        "    if test_generator is None:\n",
        "        print(f\"Cannot evaluate {model_name}: No test data available\")\n",
        "        return {}\n",
        "\n",
        "    print(f\"\\nEvaluating {model_name}...\")\n",
        "\n",
        "    # Get predictions for all test data\n",
        "    all_predictions = []\n",
        "    all_true_labels = []\n",
        "\n",
        "    for i in range(len(test_generator)):\n",
        "        test_images, test_labels = test_generator[i]\n",
        "\n",
        "        if is_hybrid:\n",
        "            batch_preds = []\n",
        "            for img in test_images:\n",
        "                pred = model(np.expand_dims(img, axis=0))\n",
        "                batch_preds.append(pred)\n",
        "            predictions = np.vstack(batch_preds)\n",
        "        else:\n",
        "            predictions = model.predict(test_images, verbose=0)\n",
        "\n",
        "        all_predictions.append(predictions)\n",
        "        all_true_labels.append(test_labels)\n",
        "\n",
        "    all_predictions = np.vstack(all_predictions)\n",
        "    all_true_labels = np.vstack(all_true_labels)\n",
        "\n",
        "    predicted_classes = np.argmax(all_predictions, axis=1)\n",
        "    true_classes = np.argmax(all_true_labels, axis=1)\n",
        "\n",
        "    # Classification Report\n",
        "    class_names = list(test_generator.class_indices.keys())\n",
        "    print(f'\\n{model_name} Classification Report:')\n",
        "    print(classification_report(true_classes, predicted_classes, target_names=class_names))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'{model_name} - Confusion Matrix')\n",
        "    plt.xlabel('Predicted Classes')\n",
        "    plt.ylabel('True Classes')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Performance Metrics\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy_score(true_classes, predicted_classes),\n",
        "        'Precision': precision_score(true_classes, predicted_classes, average='weighted', zero_division=0),\n",
        "        'Recall': recall_score(true_classes, predicted_classes, average='weighted', zero_division=0),\n",
        "        'F1 Score': f1_score(true_classes, predicted_classes, average='weighted', zero_division=0),\n",
        "        'MCC': matthews_corrcoef(true_classes, predicted_classes)\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{model_name} Performance Metrics:\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def main():\n",
        "    global vit_classifier, feature_extractor, scaler, knn, gnn_model, edge_index\n",
        "\n",
        "    if train_set is None or test_set is None:\n",
        "        print(\"Cannot proceed without dataset. Please check your dataset paths.\")\n",
        "        return\n",
        "\n",
        "    num_classes = len(train_set.class_indices)\n",
        "    print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "    try:\n",
        "        vit_classifier = load_model('vit_leaf_classifier.keras')\n",
        "        print(\"Loaded pretrained Vision Transformer model.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load existing model: {e}\")\n",
        "        print(\"Creating new Vision Transformer model...\")\n",
        "        vit_classifier, vit_base = create_vit_model(num_classes)\n",
        "\n",
        "        # Training callbacks\n",
        "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "        # Train the model\n",
        "        print(\"Training Vision Transformer...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        vit_history = vit_classifier.fit(\n",
        "            train_set,\n",
        "            validation_data=test_set,\n",
        "            epochs=100,\n",
        "            steps_per_epoch=len(train_set),\n",
        "            validation_steps=len(test_set),\n",
        "            callbacks=[reduce_lr, early_stopping],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "        print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "        # Save model\n",
        "        vit_classifier.save('vit_leaf_classifier.keras')\n",
        "        print(\"Saved trained Vision Transformer model.\")\n",
        "\n",
        "        # Plot training history\n",
        "        plt.figure(figsize=(12, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(vit_history.history['accuracy'], label='Train Accuracy')\n",
        "        plt.plot(vit_history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Accuracy Over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(vit_history.history['loss'], label='Train Loss')\n",
        "        plt.plot(vit_history.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Loss Over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    print(\"Setting up feature extractor...\")\n",
        "    feature_extractor = Model(\n",
        "        inputs=vit_classifier.input,\n",
        "        outputs=vit_classifier.layers[-3].output\n",
        "    )\n",
        "\n",
        "    # Extract features\n",
        "    train_features, train_labels = get_features(train_set, feature_extractor)\n",
        "    test_features, test_labels = get_features(test_set, feature_extractor)\n",
        "\n",
        "    # Scale features\n",
        "    print(\"Scaling features...\")\n",
        "    scaler = StandardScaler()\n",
        "    train_features_scaled = scaler.fit_transform(train_features)\n",
        "    test_features_scaled = scaler.transform(test_features)\n",
        "\n",
        "    # Train KNN\n",
        "    print(\"Training KNN classifier...\")\n",
        "    knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
        "    knn.fit(train_features_scaled, np.argmax(train_labels, axis=1))\n",
        "\n",
        "    # Create and train GNN\n",
        "    print(\"Creating and training GNN...\")\n",
        "    edge_index = create_graph(train_features_scaled, k=5)\n",
        "    gnn_model = SimpleGNN(\n",
        "        num_features=train_features_scaled.shape[1],\n",
        "        hidden_dim=64,\n",
        "        num_classes=num_classes\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.01)\n",
        "\n",
        "    # Train GNN\n",
        "    gnn_model.train()\n",
        "    for epoch in range(100):\n",
        "        optimizer.zero_grad()\n",
        "        out = gnn_model(torch.FloatTensor(train_features_scaled), edge_index)\n",
        "        loss = F.nll_loss(out, torch.LongTensor(np.argmax(train_labels, axis=1)))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 20 == 0:\n",
        "            print(f'GNN Epoch {epoch}, Loss: {loss.item():.4f}')\n",
        "\n",
        "    #hybrid prediction function\n",
        "    def hybrid_predict(image):\n",
        "        \"\"\"Hybrid prediction combining ViT, KNN, and GNN\"\"\"\n",
        "        if len(image.shape) == 3:\n",
        "            image = np.expand_dims(image, axis=0)\n",
        "\n",
        "        # ViT prediction\n",
        "        vit_pred = predict_with_tta(vit_classifier, image)\n",
        "\n",
        "        # Feature extraction\n",
        "        features = feature_extractor.predict(image, verbose=0)\n",
        "        features_scaled = scaler.transform(features)\n",
        "\n",
        "        # KNN prediction\n",
        "        knn_pred = knn.predict_proba(features_scaled)\n",
        "\n",
        "        # GNN prediction\n",
        "        with torch.no_grad():\n",
        "            gnn_model.eval()\n",
        "            single_edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
        "            gnn_out = gnn_model(torch.FloatTensor(features_scaled), single_edge_index)\n",
        "            gnn_pred = torch.exp(gnn_out).numpy()\n",
        "\n",
        "        vit_conf = np.max(vit_pred)\n",
        "        knn_conf = np.max(knn_pred)\n",
        "        gnn_conf = np.max(gnn_pred)\n",
        "\n",
        "        # Weighted average\n",
        "        final_pred = 0.7 * vit_pred + 0.2 * knn_pred + 0.1 * gnn_pred\n",
        "        return final_pred\n",
        "\n",
        "    # Evaluate models\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"MODEL EVALUATION\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Evaluate ViT model\n",
        "    vit_metrics = evaluate_model_corrected(vit_classifier, test_set, \"Vision Transformer\")\n",
        "\n",
        "    # Evaluate Hybrid model\n",
        "    hybrid_metrics = evaluate_model_corrected(hybrid_predict, test_set, \"Hybrid ViT+KNN+GNN\", is_hybrid=True)\n",
        "\n",
        "    # Compare results\n",
        "    if vit_metrics and hybrid_metrics:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"MODEL COMPARISON\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"{'Metric':<15} {'ViT':<10} {'Hybrid':<10}\")\n",
        "        print(\"-\" * 35)\n",
        "        for metric in vit_metrics.keys():\n",
        "            print(f\"{metric:<15} {vit_metrics[metric]:<10.4f} {hybrid_metrics[metric]:<10.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        import tensorflow as tf\n",
        "        if hasattr(tf.keras.mixed_precision, 'set_global_policy'):\n",
        "            tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "            print(\"Mixed precision enabled\")\n",
        "        else:\n",
        "            print(\"Mixed precision not available in this TensorFlow version\")\n",
        "    except Exception as e:\n",
        "        print(f\"Mixed precision setup failed: {e}\")\n",
        "\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9q0MpN81q57s",
        "outputId": "721f33c7-a6e7-482e-fb53-1a596b4cb87d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.19)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "TensorFlow version: 2.19.0\n",
            "GPU Available: []\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-940698548.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Mount Google Drive (Colab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/New Plant Diseases Dataset(Augmented)/train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mtest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/New Plant Diseases Dataset(Augmented)/valid'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}